competition: "FeedBack-Prize-English-Language-Learning"
text: ''

seed: 42
model_name: "microsoft/deberta-xlarge"
train_batch_size: 2
valid_batch_size: 8

max_length: 512
learning_rate: 1e-6
epochs: 2

#scheduler: 'linear'
#min_lr       : 1e-6
#T_max        : 500
scheduler: null

# 勾配累積を行うか
# n_accumulate: 1
weight_decay: 0.05

fold: -1  # <0だと全foldで実行
n_fold: 4
num_classes: 3

num_warmup_steps: 100
num_train_steps: 1000

model_save: ./models

# コンペデータのルートパス
data_root_path: ../data/feedback-prize-english-language-learning
dataset_type: "train"

#val_check_interval: 0.99
val_check_interval: 0.05
#evaluate_after_steps: 2500
evaluate_after_steps: 0

#gradient_checkpointing: true
precision: 16
gradient_checkpointing: false
#precision: 32

use_multi_dropout: true
